{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8418586,"sourceType":"datasetVersion","datasetId":4967555}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport logging\nimport json\nfrom collections import defaultdict\n\npropaganda_techniques = ['Appeal_to_Values', 'Loaded_Language', 'Consequential_Oversimplification',\n                         'Causal_Oversimplification', 'Questioning_the_Reputation', 'Straw_Man', 'Repetition',\n                         'Guilt_by_Association', 'Appeal_to_Hypocrisy', 'Conversation_Killer',\n                         'False_Dilemma-No_Choice', 'Whataboutism', 'Slogans',\n                         'Obfuscation-Vagueness-Confusion',\n                         'Name_Calling-Labeling', 'Flag_Waving', 'Doubt',\n                         'Appeal_to_Fear-Prejudice', 'Exaggeration-Minimisation', 'Red_Herring',\n                         'Appeal_to_Popularity', 'Appeal_to_Authority', 'Appeal_to_Time']\n\n\ndef load_json_as_list(fname):\n    labels_per_par = defaultdict(list)\n\n    with open(fname, 'r', encoding=\"utf-8\") as inf:\n        for i,line in enumerate(inf):\n            jobj = json.loads(line)\n            par_id = jobj['id']\n\n            labels = jobj['labels']\n\n            per_par_labels = []\n\n            for label in labels:\n                start = label['start']\n                end = label['end']\n\n                per_par_labels.append((label['technique'], [start, end]))\n\n            per_par_labels = sort_spans(per_par_labels)\n\n            labels_per_par[par_id] = per_par_labels\n\n    return labels_per_par\n\n\ndef compute_technique_frequency(annotations, technique_name):\n    all_annotations = []\n    for example_id, annot in annotations.items():\n        for x in annot:\n            all_annotations.append(x[0])\n\n    techn_freq = sum([1 for a in all_annotations if a == technique_name])\n\n    return techn_freq\n\n\ndef compute_span_score(gold_annots, pred_annots):\n    # count total no of annotations\n    prec_denominator = sum([len(pred_annots[x]) for x in pred_annots])\n    rec_denominator = sum([len(gold_annots[x]) for x in gold_annots])\n\n    technique_Spr_prec = {propaganda_technique: 0 for propaganda_technique in propaganda_techniques}\n    technique_Spr_rec = {propaganda_technique: 0 for propaganda_technique in propaganda_techniques}\n    cumulative_Spr_prec, cumulative_Spr_rec = (0, 0)\n    f1_articles = []\n\n    for example_id, pred_annot_obj in pred_annots.items():\n        gold_annot_obj = gold_annots[example_id]\n        # print(\"%s\\t%d\\t%d\" % (example_id, len(gold_annot_obj), len(pred_annot_obj)))\n\n        document_cumulative_Spr_prec, document_cumulative_Spr_rec = (0, 0)\n        for j, pred_ann in enumerate(pred_annot_obj):\n            s = \"\"\n            ann_length = pred_ann[1][1] - pred_ann[1][0]\n\n            for i, gold_ann in enumerate(gold_annot_obj):\n                if pred_ann[0] == gold_ann[0]:\n                    # print(pred_ann, gold_ann)\n\n                    # s += \"\\tmatch %s %s-%s - %s %s-%s\"%(sd[0],sd[1], sd[2], gd[0], gd[1], gd[2])\n                    intersection = span_intersection(gold_ann[1], pred_ann[1])\n                    # print(intersection)\n                    # print(intersection)\n                    s_ann_length = gold_ann[1][1] - gold_ann[1][0]\n                    Spr_prec = intersection / ann_length\n                    document_cumulative_Spr_prec += Spr_prec\n                    cumulative_Spr_prec += Spr_prec\n                    s += \"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/|p| = %d/%d = %f (cumulative S(p,r)=%f)\\n\" \\\n                         % (pred_ann[0], pred_ann[1][0], pred_ann[1][1], gold_ann[0],\n                            gold_ann[1][0], gold_ann[1][1], intersection, ann_length, Spr_prec,\n                            cumulative_Spr_prec)\n                    technique_Spr_prec[gold_ann[0]] += Spr_prec\n\n                    Spr_rec = intersection / s_ann_length\n                    document_cumulative_Spr_rec += Spr_rec\n                    cumulative_Spr_rec += Spr_rec\n                    s += \"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/|r| = %d/%d = %f (cumulative S(p,r)=%f)\\n\" \\\n                         % (pred_ann[0], pred_ann[1][0], pred_ann[1][1], gold_ann[0],\n                            gold_ann[1][0], gold_ann[1][1], intersection, s_ann_length, Spr_rec,\n                            cumulative_Spr_rec)\n                    technique_Spr_rec[gold_ann[0]] += Spr_rec\n\n        p_article, r_article, f1_article = compute_prec_rec_f1(document_cumulative_Spr_prec,\n                                                               len(pred_annot_obj),\n                                                               document_cumulative_Spr_rec,\n                                                               len(gold_annot_obj))\n        f1_articles.append(f1_article)\n\n    p, r, f1 = compute_prec_rec_f1(cumulative_Spr_prec, prec_denominator, cumulative_Spr_rec, rec_denominator)\n\n    f1_per_technique = []\n\n    for technique_name in technique_Spr_prec.keys():\n        prec_tech, rec_tech, f1_tech = compute_prec_rec_f1(technique_Spr_prec[technique_name],\n                                                           compute_technique_frequency(pred_annots,\n                                                                                       technique_name),\n                                                           technique_Spr_prec[technique_name],\n                                                           compute_technique_frequency(gold_annots,\n                                                                                       technique_name))\n        f1_per_technique.append(f1_tech)\n\n    return p, r, f1, f1_per_technique\n\n\n# if per_label is true, the scorer returns F1 score per technique\ndef FLC_score_to_string(gold_annotations, user_annotations, per_label):\n    precision, recall, f1, f1_per_class = compute_span_score(gold_annotations, user_annotations)\n\n    if per_label:\n        res_for_screen = f\"\\nF1=%f\\nPrecision=%f\\nRecall=%f\\n%s\\n\" % (f1, precision, recall, \"\\n\".join(\n            [\"F1_\" + pr + \"=\" + str(f) for pr, f in\n             zip(propaganda_techniques, f1_per_class)]))\n    else:\n        average = sum(f1_per_class) / len(f1_per_class)\n        res_for_screen = f\"Micro-F1\\tMacro-F1\\tPrecision\\tRecall\\n%f\\t%f\\t%f\\t%f\" % (f1, average, precision, recall)\n\n    res_for_script = \"%f\\t%f\\t%f\\t\" % (f1, precision, recall)\n    res_for_script += \"\\t\".join([str(x) for x in f1_per_class])\n\n    return res_for_screen\n\n\ndef sort_spans(spans):\n    \"\"\"\n    sort the list of annotations with respect to the starting offset\n    \"\"\"\n    spans = sorted(spans, key=lambda span: span[1][0])\n\n    return spans\n\n\ndef compute_prec_rec_f1(prec_numerator, prec_denominator, rec_numerator, rec_denominator):\n    p, r, f1 = (0, 0, 0)\n    if prec_denominator > 0:\n        p = prec_numerator / prec_denominator\n    if rec_denominator > 0:\n        r = rec_numerator / rec_denominator\n    if prec_denominator == 0 and rec_denominator == 0:\n        f1 = 1.0\n    if p > 0 and r > 0:\n        f1 = 2 * (p * r / (p + r))\n\n    return p, r, f1\n\n\ndef span_intersection(gold_span, pred_span):\n    x = range(gold_span[0], gold_span[1])\n    y = range(pred_span[0], pred_span[1])\n    inter = set(x).intersection(y)\n    return len(inter)\n\n\ndef validate_files(pred_file):\n    base = os.path.basename(pred_file)\n    file_basename = os.path.splitext(base)[0]\n    subtask = file_basename.split('_')[0]\n\n    logging.info(\"Validating if passed files exist...\")\n\n    if not os.path.exists(pred_file):\n        logging.error(\"File doesn't exist: {}\".format(pred_file))\n        return False\n\n    # Check if the filename matches what is required by the task\n    subtasks = [\"task1\", 'task2']\n\n    if not any(file_basename.startswith(st_name) for st_name in subtasks):\n        logging.error(\"The submission file must start by task name! possible prefixes: \" + str(subtasks))\n        return False\n\n    return subtask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T08:57:37.536684Z","iopub.execute_input":"2024-05-15T08:57:37.537336Z","iopub.status.idle":"2024-05-15T08:57:37.574407Z","shell.execute_reply.started":"2024-05-15T08:57:37.537299Z","shell.execute_reply":"2024-05-15T08:57:37.572850Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"gold_annotations = load_json_as_list('/kaggle/input/checker/araieval24_task1_test_gold.jsonl')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:57:39.804797Z","iopub.execute_input":"2024-05-15T08:57:39.805419Z","iopub.status.idle":"2024-05-15T08:57:39.832796Z","shell.execute_reply.started":"2024-05-15T08:57:39.805387Z","shell.execute_reply":"2024-05-15T08:57:39.831497Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"user_annotations = load_json_as_list('/kaggle/input/checker/task1_cuet_sstm.jsonl')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:57:41.025596Z","iopub.execute_input":"2024-05-15T08:57:41.025999Z","iopub.status.idle":"2024-05-15T08:57:41.120992Z","shell.execute_reply.started":"2024-05-15T08:57:41.025968Z","shell.execute_reply":"2024-05-15T08:57:41.119879Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"res_for_output = FLC_score_to_string(gold_annotations, user_annotations, False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:57:43.954153Z","iopub.execute_input":"2024-05-15T08:57:43.954542Z","iopub.status.idle":"2024-05-15T08:57:44.064390Z","shell.execute_reply.started":"2024-05-15T08:57:43.954513Z","shell.execute_reply":"2024-05-15T08:57:44.063168Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(res_for_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:57:45.522246Z","iopub.execute_input":"2024-05-15T08:57:45.522627Z","iopub.status.idle":"2024-05-15T08:57:45.528673Z","shell.execute_reply.started":"2024-05-15T08:57:45.522598Z","shell.execute_reply":"2024-05-15T08:57:45.527307Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Micro-F1\tMacro-F1\tPrecision\tRecall\n0.299453\t0.150559\t0.314207\t0.286023\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}